<!DOCTYPE html>
<html>
    <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" >
    <title>
        
        Optical Character Recognition · Shengbin&#39;s Studio
        
    </title>
    <link rel="icon" href= /assets/favicon2.ico>
    <!-- TODO: 在font-face加载完毕后改变字体  -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.28/webfontloader.js"></script>
    <!-- 提前加载place holder  -->
    <style type="text/css">
        @font-face {
            font-family: 'Oswald-Regular';
            src: url(/font/Oswald-Regular.ttf);
        }
    </style>
    <style type="text/css">
        .site-intro {
            position: relative;
            width: 100%;
            height: 50vh;
            overflow: hidden;
            box-shadow: -0.1rem 0 0.5rem 0 rgba(0, 0, 0, 0.8);
        }
        .site-intro-placeholder {
            position: absolute;
            z-index: -2;
            top: 0;
            left: 0px;
            width: calc(100% + 300px);
            height: 100%;
            background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
            background-position: center center;
            transform: translate3d(-226px, 0, 0);
            animation: gradient-move 2.5s ease-out 0s 1;
        }
        @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }
</style>
    <link rel="stylesheet" href = /css/style.css?v=20171218 />
    <script src="//cdn.staticfile.org/jquery/3.2.1/jquery.min.js" defer></script>
    
    <script src="/scripts/main.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
</head>
    
        <body class="post-body">
    
    
<header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >Shengbin&#39;s Studio.</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Optical Character Recognition</a>
            </div>
    </div>
    
    <a class="home-link" href=/>Shengbin's Studio.</a>
</header>
    <div class="wrapper">
        <div class="site-intro">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-img" style="background-image: url(http://oumn0o088.bkt.clouddn.com/post-bg.jpg)"></div>
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Optical Character Recognition
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <!-- 文章页标签  -->
            
            <div class="post-intro-meta">
                <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                <span class="post-intro-time">2017/12/23</span>
            </div>
        
    </div>
</div>
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <script>
            var browser = {
                    versions: function () {
                        var u = window.navigator.userAgent;
                        return {
                            userAgent: u,
                            trident: u.indexOf('Trident') > -1, //IE内核
                            presto: u.indexOf('Presto') > -1, //opera内核
                            webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
                            gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
                            mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
                            ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
                            android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
                            iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
                            iPad: u.indexOf('iPad') > -1, //是否为iPad
                            webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
                            weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
                            uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
                        };
                    }()
                }

            function fontLoaded(){
                console.log('font loaded');
                if (document.getElementsByClassName('site-intro-meta')) {
                    document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
                    document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
                    var postIntroTags = document.getElementsByClassName('post-intro-tags')[0],
                        postIntroMeat = document.getElementsByClassName('post-intro-meta')[0];
                        if (postIntroTags) {
                            postIntroTags.classList.add('post-fade-in');
                        }
                        if (postIntroMeat) {
                            postIntroMeat.classList.add('post-fade-in');
                        }
                    }
                }
                
            console.log("userAgent:" + browser.versions.userAgent);
            // UC不支持跨域，所以直接显示
            if (browser.versions.uc) {
                console.log("UCBrowser");
                fontLoaded();
            } else {
                WebFont.load({
                    custom: {
                        families: ['Oswald-Regular']
                    },
                    loading: function () {  //所有字体开始加载
                        // console.log('loading');
                    },
                    active: function () {  //所有字体已渲染
                        fontLoaded();
                    },
                    inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
                        console.log('inactive: timeout');
                        fontLoaded();
                    },
                    timeout: 7000 // Set the timeout to two seconds
                });
            }
        </script>
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <h3 id="Image-Segmentation"><a href="#Image-Segmentation" class="headerlink" title="Image Segmentation"></a>Image Segmentation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showImage</span><span class="params">(image)</span>:</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'IMG_0377_o.JPG'</span>, cv2.IMREAD_COLOR)</span><br><span class="line">showImage(img)</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_3_0.png" alt="png"></p>
<h4 id="Use-the-Canny-Algorithm-in-OpenCV-to-extract-the-edges"><a href="#Use-the-Canny-Algorithm-in-OpenCV-to-extract-the-edges" class="headerlink" title="Use the Canny Algorithm in OpenCV to extract the edges"></a>Use the Canny Algorithm in OpenCV to extract the edges</h4><p>Canny algorithm is applied to extracted edges in this image, then the edges can be use to local contours</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">edges = cv2.Canny(img,<span class="number">200</span>,<span class="number">240</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">8</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Original Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(edges,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Edge Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_5_0.png" alt="png"></p>
<h4 id="Find-countours-based-on-the-edges-extracted-from-image"><a href="#Find-countours-based-on-the-edges-extracted-from-image" class="headerlink" title="Find countours based on the edges extracted from image"></a>Find countours based on the edges extracted from image</h4><p>Edges found by canny is used to find contours of this images, from the images showed belowed we can see that  a lot of contours are extracted from the image.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">im2, contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL , cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">imcopy = img.copy()</span><br><span class="line">cv2.drawContours(imcopy, contours, <span class="number">-1</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">10</span>)</span><br><span class="line">showImage(imcopy)</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_7_0.png" alt="png"></p>
<h4 id="Find-the-Max-Contor-with-largest-contour-area"><a href="#Find-the-Max-Contor-with-largest-contour-area" class="headerlink" title="Find the Max Contor with largest contour area"></a>Find the Max Contor with largest contour area</h4><p>For this problem, the white paper sheet in this image has the largest contour, we can extracted the contour of this white paper sheet by finding the largest contour.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c = max(contours, key = cv2.contourArea)</span><br><span class="line">imcopy = img.copy()</span><br><span class="line">cv2.drawContours(imcopy, c, <span class="number">-1</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">10</span>)</span><br><span class="line">showImage(imcopy)</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_10_0.png" alt="png"></p>
<h4 id="Approximate-the-Contor"><a href="#Approximate-the-Contor" class="headerlink" title="Approximate the Contor"></a>Approximate the Contor</h4><p>After finding the contour of this white paper sheet, we can use Geometric shape such as rectangle or polygon to approximate this countour. From the result showed belowed, we can see that polygon did well in the shape approxiamtion.   </p>
<h5 id="rectangle-approximation"><a href="#rectangle-approximation" class="headerlink" title="rectangle approximation"></a>rectangle approximation</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">imcopy = img.copy()</span><br><span class="line">x,y,w,h = cv2.boundingRect(c)</span><br><span class="line">cv2.rectangle(imcopy,(x,y),(x+w,y+h),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">10</span>)</span><br><span class="line">showImage(imcopy)</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_13_0.png" alt="png"></p>
<h5 id="Polygon-approximation"><a href="#Polygon-approximation" class="headerlink" title="Polygon approximation"></a>Polygon approximation</h5><p>By applying polygon approximation, the 4 coner points was extracted, which can be used in the later experiment of perspective transformation.   </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">epsilon = <span class="number">0.01</span>*cv2.arcLength(c,<span class="keyword">True</span>)</span><br><span class="line">approx = cv2.approxPolyDP(c,epsilon,<span class="keyword">True</span>)</span><br><span class="line">imcopy = img.copy()</span><br><span class="line">cv2.drawContours(imcopy, [approx], <span class="number">-1</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">12</span>)</span><br><span class="line">cv2.putText(imcopy, <span class="string">'Point 1'</span>, (approx[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>], approx[<span class="number">0</span>][<span class="number">0</span>][<span class="number">1</span>]),cv2.FONT_HERSHEY_PLAIN, <span class="number">6</span>,(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">10</span>, cv2.LINE_AA)</span><br><span class="line">cv2.putText(imcopy, <span class="string">'Point 2'</span>, (approx[<span class="number">1</span>][<span class="number">0</span>][<span class="number">0</span>], approx[<span class="number">1</span>][<span class="number">0</span>][<span class="number">1</span>]),cv2.FONT_HERSHEY_PLAIN, <span class="number">6</span>,(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">10</span>, cv2.LINE_AA)</span><br><span class="line">cv2.putText(imcopy, <span class="string">'Point 3'</span>, (approx[<span class="number">2</span>][<span class="number">0</span>][<span class="number">0</span>], approx[<span class="number">2</span>][<span class="number">0</span>][<span class="number">1</span>]),cv2.FONT_HERSHEY_PLAIN, <span class="number">6</span>,(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">10</span>, cv2.LINE_AA)</span><br><span class="line">cv2.putText(imcopy, <span class="string">'Point 4'</span>, (approx[<span class="number">3</span>][<span class="number">0</span>][<span class="number">0</span>], approx[<span class="number">3</span>][<span class="number">0</span>][<span class="number">1</span>]),cv2.FONT_HERSHEY_PLAIN, <span class="number">6</span>,(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">10</span>, cv2.LINE_AA)</span><br><span class="line">showImage(imcopy)</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_15_0.png" alt="png"></p>
<h4 id="Applied-Perspective-Transformation"><a href="#Applied-Perspective-Transformation" class="headerlink" title="Applied Perspective Transformation"></a>Applied Perspective Transformation</h4><ul>
<li>Projective transformation(Perspective transformation) is the combination of affine transformation and projective wrap.<br>Suppose(x, y, 1) is a point in homogeneous coordinate. The projective transformation of this point is as followed.  <script type="math/tex; mode=display">
\begin{bmatrix}
  x'\\
  y'\\
  w'\\
\end{bmatrix}
=
\begin{bmatrix}
  a & b & c \\
  d & e & f \\
  g & h & 1 \\
\end{bmatrix}
*
\begin{bmatrix}
  x\\
  y\\
  1\\
\end{bmatrix}</script></li>
</ul>
<p>This 8 parameters matrix maps point$(x,y,1)$ in one projective to point $(x’/w’,y’/w’,1)$ in another projective.  </p>
<script type="math/tex; mode=display">
x' =  \frac{ax+by+c}{gx+hy}</script><script type="math/tex; mode=display">
y' =  \frac{dx+ey+f}{gx+hy}</script><p>We can get 2 equations from one point mapping, to solve this 8 parameter tranformation equation, we need more than 4 points mapping. When this tranformation equation be solved, can can applied it to get a new image.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">imcopy = img.copy()</span><br><span class="line">pts1 = np.float32(approx)</span><br><span class="line"><span class="comment">## the size is propotional to a US letter's size 425:550 = 8.5:11</span></span><br><span class="line">pts2 = np.float32([[<span class="number">0</span>,<span class="number">550</span>],[<span class="number">425</span>,<span class="number">550</span>],[<span class="number">425</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>]])</span><br><span class="line">M = cv2.getPerspectiveTransform(pts1,pts2)</span><br><span class="line">dst = cv2.warpPerspective(imcopy,M,(<span class="number">425</span>,<span class="number">550</span>))</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">16</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(imcopy),plt.title(<span class="string">'Input'</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(dst),plt.title(<span class="string">'Output'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_18_0.png" alt="png"></p>
<h3 id="Build-a-CNN-model-with-tensorflow"><a href="#Build-a-CNN-model-with-tensorflow" class="headerlink" title="Build a CNN model with tensorflow"></a>Build a CNN model with tensorflow</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape,name)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial, name=name)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape,name)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial, name=name)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_placeholders</span><span class="params">(n_x=<span class="number">784</span>, n_y=<span class="number">10</span>)</span>:</span></span><br><span class="line">    x = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_x])</span><br><span class="line">    y_ = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_y])</span><br><span class="line">    keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">    <span class="keyword">return</span> x, y_, keep_prob</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">## first CNN layer</span></span><br><span class="line">    W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>], <span class="string">'W_conv1'</span>)</span><br><span class="line">    b_conv1 = bias_variable([<span class="number">32</span>], <span class="string">'b_conv1'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## second CNN layer</span></span><br><span class="line">    W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>], <span class="string">'W_conv2'</span>)</span><br><span class="line">    b_conv2 = bias_variable([<span class="number">64</span>], <span class="string">'b_conv2'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## fully connected layer</span></span><br><span class="line">    W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>], <span class="string">'W_fc1'</span>)</span><br><span class="line">    b_fc1 = bias_variable([<span class="number">1024</span>], <span class="string">'b_fc1'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## read out layer</span></span><br><span class="line">    W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>], <span class="string">'W_fc2'</span>)</span><br><span class="line">    b_fc2 = bias_variable([<span class="number">10</span>], <span class="string">'b_fc2'</span>)</span><br><span class="line">    </span><br><span class="line">    parameters = &#123;<span class="string">'W_conv1'</span>: W_conv1,</span><br><span class="line">                  <span class="string">'b_conv1'</span>: b_conv1,</span><br><span class="line">                  <span class="string">'W_conv2'</span>: W_conv2,</span><br><span class="line">                  <span class="string">'b_conv2'</span>: b_conv2,</span><br><span class="line">                  <span class="string">'W_fc1'</span>: W_fc1,</span><br><span class="line">                  <span class="string">'b_fc1'</span>: b_fc1,</span><br><span class="line">                  <span class="string">'W_fc2'</span>: W_fc2,</span><br><span class="line">                  <span class="string">'b_fc2'</span>: b_fc2</span><br><span class="line">                 &#125;</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_prop</span><span class="params">(x, keep_prob, parameters)</span>:</span></span><br><span class="line">    W_conv1 = parameters[<span class="string">'W_conv1'</span>]</span><br><span class="line">    b_conv1 = parameters[<span class="string">'b_conv1'</span>]</span><br><span class="line">    W_conv2 = parameters[<span class="string">'W_conv2'</span>]</span><br><span class="line">    b_conv2 = parameters[<span class="string">'b_conv2'</span>]</span><br><span class="line">    W_fc1 = parameters[<span class="string">'W_fc1'</span>]</span><br><span class="line">    b_fc1 = parameters[<span class="string">'b_fc1'</span>]</span><br><span class="line">    W_fc2 = parameters[<span class="string">'W_fc2'</span>]</span><br><span class="line">    b_fc2 = parameters[<span class="string">'b_fc2'</span>]</span><br><span class="line">    </span><br><span class="line">    x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">    h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line">    </span><br><span class="line">    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">    h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line">    </span><br><span class="line">    h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</span><br><span class="line">    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br><span class="line">    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y_conv</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    x, y_, keep_prob = create_placeholders();</span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    y_conv = forward_prop(x, <span class="number">1.0</span>, parameters)</span><br><span class="line">    print(<span class="string">"y_conv = "</span> + str(y_conv))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">16</span></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">costs = []</span><br><span class="line">x, y_, keep_prob = create_placeholders()</span><br><span class="line">parameters = initialize_parameters()</span><br><span class="line">y_conv = forward_prop(x, keep_prob, parameters)</span><br><span class="line"></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))</span><br><span class="line"><span class="comment">## Optimizer</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)</span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_conv, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        epoch_cost = <span class="number">0.0</span></span><br><span class="line">        num_minibatches = int(<span class="number">55000</span>/<span class="number">50</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1100</span>):</span><br><span class="line">            batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                train_accuracy = accuracy.eval(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>],keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">                print(<span class="string">'epoch %d, step %d, training accuracy %g'</span> % (epoch, i, train_accuracy))</span><br><span class="line"></span><br><span class="line">            _, minibatch_cost = sess.run([train_step, cross_entropy],feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>&#125;)</span><br><span class="line">            epoch_cost += minibatch_cost / num_minibatches</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Cost after epoch %i: %f"</span> % (epoch, epoch_cost))</span><br><span class="line">        costs.append(epoch_cost)</span><br><span class="line">    </span><br><span class="line">    plt.plot(np.squeeze(costs))</span><br><span class="line">    plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'iterations per epoch'</span>)</span><br><span class="line">    plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    parameters = sess.run(parameters)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Parameters have been trained!"</span>)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">'test accuracy %g'</span> % accuracy.eval(feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;))</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_8_1.png" alt="png"></p>
<pre><code>Parameters have been trained!
test accuracy 0.9927
</code></pre><h4 id="Save-the-parameters-to-local-data"><a href="#Save-the-parameters-to-local-data" class="headerlink" title="Save the parameters to local data"></a>Save the parameters to local data</h4><p>Because the CNN model takes a long long time to train, thus it will save time if we can save the trained parameters to a local file </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">pickle.dump(parameters, open(<span class="string">"params.pkl"</span>, <span class="string">"wb"</span>))</span><br></pre></td></tr></table></figure>
<h4 id="Load-data-from-saved-file"><a href="#Load-data-from-saved-file" class="headerlink" title="Load data from saved file"></a>Load data from saved file</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">testparams = pickle.load(open(<span class="string">"params.pkl"</span>,<span class="string">"rb"</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(x, parameters)</span>:</span></span><br><span class="line">    W_conv1 = tf.convert_to_tensor(parameters[<span class="string">'W_conv1'</span>])</span><br><span class="line">    b_conv1 = tf.convert_to_tensor(parameters[<span class="string">'b_conv1'</span>])</span><br><span class="line">    W_conv2 = tf.convert_to_tensor(parameters[<span class="string">'W_conv2'</span>])</span><br><span class="line">    b_conv2 = tf.convert_to_tensor(parameters[<span class="string">'b_conv2'</span>])</span><br><span class="line">    W_fc1 = tf.convert_to_tensor(parameters[<span class="string">'W_fc1'</span>])</span><br><span class="line">    b_fc1 = tf.convert_to_tensor(parameters[<span class="string">'b_fc1'</span>])</span><br><span class="line">    W_fc2 = tf.convert_to_tensor(parameters[<span class="string">'W_fc2'</span>])</span><br><span class="line">    b_fc2 = tf.convert_to_tensor(parameters[<span class="string">'b_fc2'</span>])</span><br><span class="line">    </span><br><span class="line">    parameters = &#123;<span class="string">'W_conv1'</span>: W_conv1,</span><br><span class="line">                  <span class="string">'b_conv1'</span>: b_conv1,</span><br><span class="line">                  <span class="string">'W_conv2'</span>: W_conv2,</span><br><span class="line">                  <span class="string">'b_conv2'</span>: b_conv2,</span><br><span class="line">                  <span class="string">'W_fc1'</span>: W_fc1,</span><br><span class="line">                  <span class="string">'b_fc1'</span>: b_fc1,</span><br><span class="line">                  <span class="string">'W_fc2'</span>: W_fc2,</span><br><span class="line">                  <span class="string">'b_fc2'</span>: b_fc2</span><br><span class="line">                 &#125;</span><br><span class="line">    </span><br><span class="line">    x_input = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">    </span><br><span class="line">    y_out = forward_propagation_for_predict(x_input, parameters)</span><br><span class="line">    p = tf.argmax(y_out, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    prediction = sess.run(p, feed_dict = &#123;x_input: x&#125;)</span><br><span class="line">    <span class="keyword">return</span> prediction</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation_for_predict</span><span class="params">(x, parameters)</span>:</span></span><br><span class="line">    W_conv1 = parameters[<span class="string">'W_conv1'</span>]</span><br><span class="line">    b_conv1 = parameters[<span class="string">'b_conv1'</span>]</span><br><span class="line">    W_conv2 = parameters[<span class="string">'W_conv2'</span>]</span><br><span class="line">    b_conv2 = parameters[<span class="string">'b_conv2'</span>]</span><br><span class="line">    W_fc1 = parameters[<span class="string">'W_fc1'</span>]</span><br><span class="line">    b_fc1 = parameters[<span class="string">'b_fc1'</span>]</span><br><span class="line">    W_fc2 = parameters[<span class="string">'W_fc2'</span>]</span><br><span class="line">    b_fc2 = parameters[<span class="string">'b_fc2'</span>]</span><br><span class="line">    </span><br><span class="line">    x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">    h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line">    </span><br><span class="line">    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">    h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line">    </span><br><span class="line">    h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</span><br><span class="line">    h_fc1_drop = tf.nn.dropout(h_fc1, <span class="number">1.0</span>)</span><br><span class="line">    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y_conv</span><br></pre></td></tr></table></figure>
<h4 id="Experiment-of-Self-Written-Digits-Image"><a href="#Experiment-of-Self-Written-Digits-Image" class="headerlink" title="Experiment of Self-Written Digits Image"></a>Experiment of Self-Written Digits Image</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">'test_digit4.png'</span>, cv2.IMREAD_COLOR)</span><br><span class="line">img = cv2.cvtColor( img, cv2.COLOR_RGB2GRAY )</span><br><span class="line">im_gray = cv2.GaussianBlur(img, (<span class="number">5</span>, <span class="number">5</span>), <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">plt.imshow(im_gray, cmap = <span class="string">'gray'</span>, interpolation = <span class="string">'bicubic'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_18_0_2.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blur_img = cv2.GaussianBlur(img, (<span class="number">5</span>,<span class="number">5</span>), <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ret,thresh = cv2.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv2.THRESH_BINARY_INV)</span><br><span class="line">im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL , cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">rects = [cv2.boundingRect(contour) <span class="keyword">for</span> contour <span class="keyword">in</span> contours]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(thresh, cmap = <span class="string">'gray'</span>, interpolation = <span class="string">'bicubic'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_21_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateImage</span><span class="params">(small)</span>:</span></span><br><span class="line">    row, col = small.shape</span><br><span class="line">    </span><br><span class="line">    small = cv2.resize(small, (<span class="number">20</span>*col//row, <span class="number">20</span>), interpolation=cv2.INTER_AREA)</span><br><span class="line">    <span class="comment">##small = cv2.dilate(small, (3, 3))</span></span><br><span class="line">    small = cv2.dilate(small, (<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">    blank_image = np.zeros((<span class="number">28</span>,<span class="number">28</span>), np.uint8)</span><br><span class="line">    row, col = small.shape</span><br><span class="line">    shift_x = (<span class="number">28</span> - row) // <span class="number">2</span></span><br><span class="line">    shift_y = (<span class="number">28</span> - col) // <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,row):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,col):</span><br><span class="line">            blank_image[i+shift_x][j+shift_y] = small[i][j]</span><br><span class="line">    <span class="keyword">return</span> blank_image</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">images = []</span><br><span class="line"><span class="keyword">for</span> i, rect <span class="keyword">in</span> enumerate(rects):</span><br><span class="line">    <span class="comment"># Draw the rectangles</span></span><br><span class="line">    cv2.rectangle(img, (rect[<span class="number">0</span>], rect[<span class="number">1</span>]), (rect[<span class="number">0</span>] + rect[<span class="number">2</span>], rect[<span class="number">1</span>] + rect[<span class="number">3</span>]), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">3</span>) </span><br><span class="line">    <span class="comment"># Make the rectangular region around the digit</span></span><br><span class="line">    width = int(rect[<span class="number">3</span>] * <span class="number">1.1</span>)</span><br><span class="line">    height = int(rect[<span class="number">2</span>] * <span class="number">1.1</span>)</span><br><span class="line">    pt1 = int(rect[<span class="number">1</span>] + rect[<span class="number">3</span>] // <span class="number">2</span> - width // <span class="number">2</span>)</span><br><span class="line">    pt2 = int(rect[<span class="number">0</span>] + rect[<span class="number">2</span>] // <span class="number">2</span> - height // <span class="number">2</span>)</span><br><span class="line">    roi = thresh[pt1:pt1+width, pt2:pt2+height]</span><br><span class="line">    <span class="comment"># Resize the image</span></span><br><span class="line">    roi = generateImage(roi)</span><br><span class="line">    <span class="comment"># dilate the image</span></span><br><span class="line">    images.append(roi)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig=plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i, image <span class="keyword">in</span> enumerate(images):</span><br><span class="line">    <span class="comment">#image = cv2.bitwise_not(image)</span></span><br><span class="line">    sub_fig = fig.add_subplot(<span class="number">2</span>,<span class="number">5</span>,i+<span class="number">1</span>)</span><br><span class="line">    sub_fig.imshow(image, cmap = <span class="string">'gray'</span>, interpolation = <span class="string">'bicubic'</span>)</span><br><span class="line">    images[i] = image</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_24_0.png" alt="png"></p>
<h4 id="Test-my-Own-hand-written"><a href="#Test-my-Own-hand-written" class="headerlink" title="Test my Own hand written"></a>Test my Own hand written</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fig_out=plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> i, image <span class="keyword">in</span> enumerate(images):</span><br><span class="line">    test_im = np.array([image.reshape(<span class="number">28</span>*<span class="number">28</span>)], <span class="string">'float32'</span>)</span><br><span class="line">    my_image_prediction=predict(test_im, testparams)</span><br><span class="line">    label = np.squeeze(my_image_prediction)</span><br><span class="line">    sub_fig = fig_out.add_subplot(<span class="number">2</span>,<span class="number">5</span>,i+<span class="number">1</span>)</span><br><span class="line">    sub_fig.annotate(label, xy=(<span class="number">2</span>, <span class="number">1</span>),size= <span class="number">25</span>,color=<span class="string">'#ee8d18'</span>, xytext=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">    sub_fig.imshow(image.reshape(<span class="number">28</span>,<span class="number">28</span>), cmap = <span class="string">'gray'</span>, interpolation = <span class="string">'bicubic'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Optical-Character-Recognition/output_26_0.png" alt="png"></p>

    </article>
    <!-- 前后页  -->
    <ul class="post-pager">
        
            <li class="next">
                <a href= "/2018/02/01/Deep-Neural-NetWork-Sorting/" title= Deep Neural NetWork Sorting >
                    <span>Next Post</span>
                    <span>Deep Neural NetWork Sorting</span>
                </a>
            </li>
        
        
            <li class="previous">
                <a href= "/2017/12/23/Speech-Recognition/" title= Speech Recognition >
                    <span>Previous Post</span>
                    <span>Speech Recognition</span>
                </a>
            </li>
        
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
<div id="container"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
    var gitment = new Gitment({
        id: "Optical Character Recognition", // 可选。默认为 location.href
        owner: 'wushbin',
        repo: 'wushbin.github.io',
        oauth: {
            client_id: '17eb7cee5fa4bc08355b',
            client_secret: '176f2991889fafe11f2ae7670c5f1dbe879ce0eb',
        },
    })
    gitment.render('container')

</script>

    <!--PC版-->

    <!--PC版-->


    
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:ngshbin@gmail.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/wushbin" class="iconfont-archer github" target="_blank" title="github"></a>
            
        
    
        
    
        
            
                <a href="https://www.linkedin.com/in/shengbin-wu/" class="iconfont-archer linkedin" target="_blank" title="linkedin"></a>
            
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">Theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper">
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Image-Segmentation"><span class="toc-number">1.</span> <span class="toc-text">Image Segmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Use-the-Canny-Algorithm-in-OpenCV-to-extract-the-edges"><span class="toc-number">1.1.</span> <span class="toc-text">Use the Canny Algorithm in OpenCV to extract the edges</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Find-countours-based-on-the-edges-extracted-from-image"><span class="toc-number">1.2.</span> <span class="toc-text">Find countours based on the edges extracted from image</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Find-the-Max-Contor-with-largest-contour-area"><span class="toc-number">1.3.</span> <span class="toc-text">Find the Max Contor with largest contour area</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Approximate-the-Contor"><span class="toc-number">1.4.</span> <span class="toc-text">Approximate the Contor</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#rectangle-approximation"><span class="toc-number">1.4.1.</span> <span class="toc-text">rectangle approximation</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Polygon-approximation"><span class="toc-number">1.4.2.</span> <span class="toc-text">Polygon approximation</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Applied-Perspective-Transformation"><span class="toc-number">1.5.</span> <span class="toc-text">Applied Perspective Transformation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Build-a-CNN-model-with-tensorflow"><span class="toc-number">2.</span> <span class="toc-text">Build a CNN model with tensorflow</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Save-the-parameters-to-local-data"><span class="toc-number">2.1.</span> <span class="toc-text">Save the parameters to local data</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Load-data-from-saved-file"><span class="toc-number">2.2.</span> <span class="toc-text">Load data from saved file</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Experiment-of-Self-Written-Digits-Image"><span class="toc-number">2.3.</span> <span class="toc-text">Experiment of Self-Written Digits Image</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Test-my-Own-hand-written"><span class="toc-number">2.4.</span> <span class="toc-text">Test my Own hand written</span></a></li></ol></li></ol>
    </div>
    
    <div class="back-top">&#xe639;</div>
    <div class="sidebar">
    <div class="sidebar-header sidebar-header-show-archive">
        <div class="sidebar-category">
            <span class="sidebar-archive-link"><span class="iconfont-archer">&#xe67d;</span>Archive</span>
            <span class="sidebar-tags-link"><span class="iconfont-archer">&#xe610;</span>Tag</span>
        </div>
    </div>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-archive">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-archive"> Total : 13 </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2018 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/12</span><a class="archive-post-title" href= "/2018/04/12/Kmeans/" >K means and Kernel K means</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/01</span><a class="archive-post-title" href= "/2018/03/01/Support-Vector-Machine-Implementation/" >Support Vector Machine Implementation With Python</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/02</span><a class="archive-post-title" href= "/2018/02/02/Decision-Tree/" >Decision Tree and Random Forest</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/01</span><a class="archive-post-title" href= "/2018/02/01/Deep-Neural-NetWork-Sorting/" >Deep Neural NetWork Sorting</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2017 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/23</span><a class="archive-post-title" href= "/2017/12/23/Speech-Recognition/" >Speech Recognition</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/23</span><a class="archive-post-title" href= "/2017/12/23/Optical-Character-Recognition/" >Optical Character Recognition</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/12</span><a class="archive-post-title" href= "/2017/10/12/Sharing-On-Campus-Web-Application/" >Sharing On Campus: Web Application</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/09</span><a class="archive-post-title" href= "/2017/10/09/Word-Embedding-Syntactics-or-Semantics/" >Word Embedding: Syntactics or Semantics</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/23</span><a class="archive-post-title" href= "/2017/09/23/Hidden-Markov-Model-for-Part-of-Speech-Tagging/" >Hidden Markov Model for Part of Speech Tagging</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/02</span><a class="archive-post-title" href= "/2017/05/02/cat-and-dog/" >cat-and-dog</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/01</span><a class="archive-post-title" href= "/2017/05/01/Duke-Gather-Android-Application/" >Duke Gather: Android Application</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2016 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/01</span><a class="archive-post-title" href= "/2016/06/01/High-Speed-Test-Rig-Development/" >High Speed Test Rig Development</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2013 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/01</span><a class="archive-post-title" href= "/2013/06/01/SCARA-Robot/" >SCARA Robot</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name"><a href= "#">machine learning</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Java</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Mobile Application</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">natural language processing</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">mechanical design</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">experiment</a></span>
    
    </div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: false
    tags: true</pre>
    </div> 
    <div class="sidebar-tag-list"></div>
</div>
    </div>
</div> 
    <script>
    var jsInfo = {
        root: '/'
    }
</script>
    <!-- 不蒜子  -->
    
    <!-- CNZZ统计  -->
    
    </div>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>

<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

</body>
</html>


