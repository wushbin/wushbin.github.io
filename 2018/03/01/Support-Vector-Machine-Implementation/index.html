<!DOCTYPE html>
<html>
    <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" >
    <title>
        
        Support Vector Machine Implementation With Python · Shengbin&#39;s Studio
        
    </title>
    <link rel="icon" href= /assets/favicon2.ico>
    <!-- TODO: 在font-face加载完毕后改变字体  -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.28/webfontloader.js"></script>
    <!-- 提前加载place holder  -->
    <style type="text/css">
        @font-face {
            font-family: 'Oswald-Regular';
            src: url(/font/Oswald-Regular.ttf);
        }
    </style>
    <style type="text/css">
        .site-intro {
            position: relative;
            width: 100%;
            height: 50vh;
            overflow: hidden;
            box-shadow: -0.1rem 0 0.5rem 0 rgba(0, 0, 0, 0.8);
        }
        .site-intro-placeholder {
            position: absolute;
            z-index: -2;
            top: 0;
            left: 0px;
            width: calc(100% + 300px);
            height: 100%;
            background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
            background-position: center center;
            transform: translate3d(-226px, 0, 0);
            animation: gradient-move 2.5s ease-out 0s 1;
        }
        @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }
</style>
    <link rel="stylesheet" href = /css/style.css?v=20171218 />
    <script src="//cdn.staticfile.org/jquery/3.2.1/jquery.min.js" defer></script>
    
    <script src="/scripts/main.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
</head>
    
        <body class="post-body">
    
    
<header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >Shengbin&#39;s Studio.</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Support Vector Machine Implementation With Python</a>
            </div>
    </div>
    
    <a class="home-link" href=/>Shengbin's Studio.</a>
</header>
    <div class="wrapper">
        <div class="site-intro">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-img" style="background-image: url(http://oumn0o088.bkt.clouddn.com/post-bg.jpg)"></div>
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Support Vector Machine Implementation With Python
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <!-- 文章页标签  -->
            
                <div class= post-intro-tags >
    
        <a class="post-tag" href="javascript:void(0);" data-href = machine learning>machine learning</a>
    
</div>
            
            <div class="post-intro-meta">
                <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                <span class="post-intro-time">2018/03/01</span>
            </div>
        
    </div>
</div>
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <script>
            var browser = {
                    versions: function () {
                        var u = window.navigator.userAgent;
                        return {
                            userAgent: u,
                            trident: u.indexOf('Trident') > -1, //IE内核
                            presto: u.indexOf('Presto') > -1, //opera内核
                            webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
                            gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
                            mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
                            ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
                            android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
                            iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
                            iPad: u.indexOf('iPad') > -1, //是否为iPad
                            webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
                            weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
                            uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
                        };
                    }()
                }

            function fontLoaded(){
                console.log('font loaded');
                if (document.getElementsByClassName('site-intro-meta')) {
                    document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
                    document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
                    var postIntroTags = document.getElementsByClassName('post-intro-tags')[0],
                        postIntroMeat = document.getElementsByClassName('post-intro-meta')[0];
                        if (postIntroTags) {
                            postIntroTags.classList.add('post-fade-in');
                        }
                        if (postIntroMeat) {
                            postIntroMeat.classList.add('post-fade-in');
                        }
                    }
                }
                
            console.log("userAgent:" + browser.versions.userAgent);
            // UC不支持跨域，所以直接显示
            if (browser.versions.uc) {
                console.log("UCBrowser");
                fontLoaded();
            } else {
                WebFont.load({
                    custom: {
                        families: ['Oswald-Regular']
                    },
                    loading: function () {  //所有字体开始加载
                        // console.log('loading');
                    },
                    active: function () {  //所有字体已渲染
                        fontLoaded();
                    },
                    inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
                        console.log('inactive: timeout');
                        fontLoaded();
                    },
                    timeout: 7000 // Set the timeout to two seconds
                });
            }
        </script>
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <p>In this post, a SVM classifier is implemented. The SVM is implemented with “Hard Margin” and “Soft Margin”.  The “Hard Margin” is used to classify separable data, while the soft margin is used to classifier inseparable data. In addition, kernel can be used in this SVM classifier. In this post, the SVM is implemented with linear kernel and Gaussian Kernel(RBF kernel).  </p>
<h3 id="SVM-Classifier"><a href="#SVM-Classifier" class="headerlink" title="SVM Classifier"></a>SVM Classifier</h3><p>We will use a Quadratic Program Solver CVXOPT to solve the Lagrangian of SVM. A tutorial of CVXOPT can be found here (<a href="https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf" target="_blank" rel="noopener">cvsopt</a>).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cvxopt</span><br><span class="line"><span class="keyword">from</span> cvxopt <span class="keyword">import</span> matrix</span><br><span class="line"><span class="keyword">from</span> cvxopt <span class="keyword">import</span> solvers</span><br></pre></td></tr></table></figure></p>
<h4 id="Hard-Margin-SVM"><a href="#Hard-Margin-SVM" class="headerlink" title="Hard Margin SVM"></a>Hard Margin SVM</h4><p>The Primal problem of SVM is </p>
<script type="math/tex; mode=display">min_{\lambda, \lambda_0} \frac{1}{2}||\lambda||^2_2  \text{ }\text{ }\text{  s.t.  } y_i(\lambda^Tx_i + \lambda_0) - 1 \geq 0</script><p>The Lagrangian of SVM is </p>
<script type="math/tex; mode=display">\mathcal{L}([\lambda, \lambda_0], \alpha) = \frac{1}{2} \sum_{j=1}^n \lambda_j^2 + \sum_{i=1}^n \alpha_i[-y_i(\lambda^Tx_i + \lambda_0) + 1]</script><p>The $KKT$ condition is </p>
<script type="math/tex; mode=display">\nabla_{\lambda}\mathcal{L} = \lambda - \sum_{i=1}^n\alpha_iy_ix_i = 0 \implies \lambda = \sum_{i=1}^n \alpha_iy_ix_i</script><script type="math/tex; mode=display">\frac{\partial}{\partial \lambda_0}\mathcal{L} = -\sum_{i=1}^n\alpha_iy_i = 0</script><script type="math/tex; mode=display">\alpha_i \geq 0</script><script type="math/tex; mode=display">\alpha_i[-y_i(\lambda^Tx_i + \lambda_0) + 1] = 0</script><script type="math/tex; mode=display">-y_i(\lambda^Tx_i + \lambda_0) + 1 \leq 0</script><p>The Dual Problem is </p>
<script type="math/tex; mode=display">max_{\alpha}\mathcal{L}(\alpha) = \sum_{i=1}^n\alpha_i - \frac{1}{2}\sum_{i,j}\alpha_i\alpha_ky_iy_kx_i^Tx_k</script><script type="math/tex; mode=display">s.t. \text{     }\alpha_i \geq 0 \text{  }\forall i  \text{   and   } \sum_{i=1}^n \alpha_iy_i = 0</script><p>This dual problem can be solved by a quadratic program solver.<br>That is </p>
<script type="math/tex; mode=display">min_{\alpha}: \frac{1}{2}\sum_{i,j}\alpha_i\alpha_ky_iy_kx_i^Tx_k - \sum_{i=1}^n\alpha_i</script><script type="math/tex; mode=display">min_{\mathbf{\alpha}}: \frac{1}{2} \mathbf{\alpha}^T \mathbf{P} \mathbf{\alpha} + \mathbf{q}^T\mathbf{\alpha}</script><script type="math/tex; mode=display">
\mathbf{P} = 
\begin{bmatrix}
y_1y_1\mathbf{x_1}^T\mathbf{x_1} & \dots & y_1y_n\mathbf{x_1}^T\mathbf{x_n} \\
\dots & \dots & \dots \\
y_ny_1\mathbf{x_n}^T\mathbf{x_1} & \dots & y_ny_n\mathbf{x_n}^T\mathbf{x_n} \\
\end{bmatrix}</script><script type="math/tex; mode=display">\mathbf{q} = [-1,-1,-1,\dots, -1]^T</script><script type="math/tex; mode=display">s.t. \begin{cases}
\mathbf{G}\mathbf{\alpha} \leq \mathbf{h} \\
\mathbf{A} \mathbf{\alpha} = \mathbf{b}\\
 \end{cases}</script><script type="math/tex; mode=display">\mathbf{G} = -1 \times \mathbf{I_{n\times n}}</script><script type="math/tex; mode=display">\mathbf{h} = [0,0,0,\dots,0]^T</script><script type="math/tex; mode=display">A = [y_1, y_2, y_3, \dots, y_n]^T</script><script type="math/tex; mode=display">b = 0</script><p>The optimal value of $\alpha_i$ can be obtained by solving the above quadratic problem using CVXOPT.</p>
<h5 id="Making-prediction-using-Linear-Kernel"><a href="#Making-prediction-using-Linear-Kernel" class="headerlink" title="Making prediction using Linear Kernel"></a>Making prediction using Linear Kernel</h5><p>For linear kernel, we make prediction by $f(x<em>{new}) = \mathbf{\lambda}^{\star T}\mathbf{x</em>{new} + \lambda_0^{\star}}$<br>we can compute the $\lambda^{\star}$ by </p>
<script type="math/tex; mode=display">\lambda^{\star} = \sum_{i=1}^n \alpha_i^{\star} y_i \mathbf{x_i}</script><p>Then we can use the $\lambda^{\star}$ and support vectors to compute $\lambda_0^{\star}$ by</p>
<script type="math/tex; mode=display">1 = y_i(\lambda^{\star T}\mathbf{x_i} + \lambda_0^{\star})</script><p>For this question, all the support vectors are used to compute the $\lambda_0^{\star}$ and then take the average as the final $\lambda_0^{\star}$</p>
<h5 id="Gaussian-Kernel-RBF"><a href="#Gaussian-Kernel-RBF" class="headerlink" title="Gaussian Kernel(RBF)"></a>Gaussian Kernel(RBF)</h5><p>For a non-linear kernel, if we do not know how the kernel map features to a new feature space, the $\lambda^{\star}$ can not be computed by $\lambda^{\star} = \sum_{i=1}^n \alpha_i^{\star} y_i \mathbf{x_i^{\mathcal{H_k}}}$ if we do not know the $\mathbf{x_i^{\mathcal{H_k}}}$<br>However, all we need to know is the value of inner product a $\mathbf{x_i^{\mathcal{H_k}}}$ in the new feature space.<br>For solving the Dual problem, </p>
<script type="math/tex; mode=display">max_{\alpha}\mathcal{L}(\alpha) = \sum_{i=1}^n\alpha_i - \frac{1}{2}\sum_{i,j}\alpha_i\alpha_ky_iy_k\langle x_i, x_k \rangle_{\mathcal{H_k}}</script><p>we just need to know the value of $\langle x_i, x_k \rangle$<br>For making prediction,</p>
<script type="math/tex; mode=display">
\begin{align}
f(x_{new}) & = \sum_j^p \lambda_j^{\star}x_{new(j)} + \lambda_0\\
& = \sum_{j}^p \sum_{i}^n \alpha_i^{\star}y_ix_{i,j} x_{new(j)} + \lambda_0^{\star}\\
& = \sum_i^n \alpha_i^{\star}y_i \sum_j^p x_{i,j} x_{new(j)} + \lambda_0^{\star}\\
& = \sum_i^n \alpha_i^{\star}y_i \langle \mathbf{x_i}, \mathbf{x_{new}}\rangle_{\mathcal{H_k}} + \lambda_0^{\star}\\
& = \sum_i^n \alpha_i^{\star}y_i k(\mathbf{x_i}, \mathbf{x_{new}}) + \lambda_0^{\star}\\
\end{align}</script><p>For this equation, we know that we just need to know the inner product value of $x$ in the new feature space to make a prediction.<br>Thus, for the SVM using Gaussian kernel, all we need is the value of two vector in the Gaussian kernel. </p>
<h4 id="Soft-Margin"><a href="#Soft-Margin" class="headerlink" title="Soft Margin"></a>Soft Margin</h4><p>The Primal problem of SVM is </p>
<script type="math/tex; mode=display">min_{\lambda, \lambda_0} \frac{1}{2}||\lambda||^2_2 + C\sum_{i=1}^n \xi_i</script><p>s.t.$\begin{cases}<br>y_i(\lambda^Tx_i + \lambda_0) \geq  1 - \xi_i\<br>\xi_i \geq 0\end{cases}$<br>The Lagrangian form of this prime is</p>
<script type="math/tex; mode=display">\mathcal{L}([\lambda, \lambda_0], \xi, \alpha, \gamma) = \frac{1}{2} \sum_{j=1}^p \lambda_j^2 + C\sum_{i=1}^n \xi_i -\sum_{i=1}^n \alpha_i[y_i(\lambda^Tx_i + \lambda_0) - 1 + \xi_i] - \sum_{i=1}^n \gamma_i\xi_i</script><p>The Dual problem is </p>
<script type="math/tex; mode=display">max_{\alpha}\mathcal{L}(\alpha) = \sum_{i=1}^n\alpha_i - \frac{1}{2}\sum_{i,j}\alpha_i\alpha_ky_iy_kx_i^Tx_k</script><script type="math/tex; mode=display">s.t. \begin{cases}
0 \leq \alpha_i \geq C \text{  }\forall i \\
\sum_{i=1}^n \alpha_iy_i = 0\\
\end{cases}</script><p>The only difference is $\leq \alpha_i \geq C \text{  }\forall i$. To solve the quadratic problem, all we need to change is the matrix $\mathbf{G}$ and $\mathbf{h}$. </p>
<script type="math/tex; mode=display">\mathbf{G} = 
\begin{bmatrix}
-\mathbf{I} \\
\mathbf{I} \\
\end{bmatrix}</script><script type="math/tex; mode=display">
\mathbf{h} = 
\begin{bmatrix}
\mathbf{0_{n\times 1}}\\
\mathbf{C_{n\times 1}}\\
\end{bmatrix}</script><p>The code of SVM implemented in Python is shown as below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVM</span>:</span></span><br><span class="line">    <span class="comment">## default kernel is linear</span></span><br><span class="line">    <span class="comment">## default sigma for gaussian kernel is 5.0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel=<span class="string">'linear'</span>, margin=<span class="string">'hard'</span>, C=<span class="number">1</span>, sigma=<span class="number">5</span>)</span>:</span></span><br><span class="line">        self.k = kernel</span><br><span class="line">        self.a = <span class="keyword">None</span></span><br><span class="line">        self.sv_x = <span class="keyword">None</span></span><br><span class="line">        self.sv_y = <span class="keyword">None</span></span><br><span class="line">        self.w = <span class="keyword">None</span></span><br><span class="line">        self.w_0 = <span class="keyword">None</span></span><br><span class="line">        self.sigma = sigma</span><br><span class="line">        self.margin = margin</span><br><span class="line">        self.C = C</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">kernel</span><span class="params">(self, x1, x2)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.k == <span class="string">'linear'</span>:</span><br><span class="line">            <span class="keyword">return</span> np.dot(x1, x2)</span><br><span class="line">        <span class="keyword">elif</span> self.k == <span class="string">'guassian'</span>:</span><br><span class="line">            <span class="keyword">return</span> np.exp(-np.linalg.norm(x1-x2)**<span class="number">2</span> / (<span class="number">2</span> * (self.sigma ** <span class="number">2</span>)))</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        caches = &#123;&#125;</span><br><span class="line">        <span class="comment">## y is (1,-1)</span></span><br><span class="line">        self.train_x = X <span class="comment">## point to the training data</span></span><br><span class="line">        self.train_y = y <span class="comment">## point to the training data</span></span><br><span class="line">        n, f = X.shape</span><br><span class="line">        P = np.zeros((n, n))</span><br><span class="line">        K = np.zeros((n,n))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">                k_ij = self.kernel(X[i], X[j])</span><br><span class="line">                P[i,j] = y[i] * y[j] * k_ij</span><br><span class="line">                K[i, j] = k_ij</span><br><span class="line">        P = matrix(P)</span><br><span class="line">        q = matrix(<span class="number">-1</span> * np.ones((n, <span class="number">1</span>)))</span><br><span class="line">        <span class="keyword">if</span> self.margin == <span class="string">'hard'</span>:</span><br><span class="line">            G = matrix(<span class="number">-1</span> * np.identity(n))</span><br><span class="line">            h = matrix(np.zeros((n, <span class="number">1</span>)))</span><br><span class="line">        <span class="keyword">if</span> self.margin == <span class="string">'soft'</span>:</span><br><span class="line">            G = matrix(np.vstack((<span class="number">-1</span> * np.identity(n), <span class="number">1</span> * np.identity(n))))</span><br><span class="line">            h = matrix(np.vstack((np.zeros((n,<span class="number">1</span>)), self.C * np.ones((n, <span class="number">1</span>)))))</span><br><span class="line">        </span><br><span class="line">        A = matrix(y.reshape(<span class="number">1</span>, n))</span><br><span class="line">        b = matrix(<span class="number">0.0</span>)</span><br><span class="line">        sol = solvers.qp(P,q,G,h,A,b)</span><br><span class="line">        a = np.ravel(sol[<span class="string">'x'</span>])</span><br><span class="line">        </span><br><span class="line">        sv_idx = np.where(a &gt; <span class="number">1e-5</span>)</span><br><span class="line">        self.sv_x = X[sv_idx]</span><br><span class="line">        self.sv_y = y[sv_idx]</span><br><span class="line">        self.a = a[sv_idx]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.k == <span class="string">'linear'</span>:</span><br><span class="line">            self.w = np.dot((self.a * self.sv_y), self.sv_x)</span><br><span class="line">            self.w_0 = np.mean(self.sv_y - np.dot(self.sv_x, self.w))</span><br><span class="line">            print(<span class="string">"The computed intercept term is &#123;0:f&#125;"</span>.format(self.w_0))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">## can not compute w</span></span><br><span class="line">            w_0s = np.zeros_like(self.a)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.a)):</span><br><span class="line">                first_term = <span class="number">0</span></span><br><span class="line">                first_term = np.dot(self.a * self.sv_y, K[sv_idx, sv_idx[<span class="number">0</span>][i]].T)</span><br><span class="line">                w_0s[i] = self.sv_y[i] - first_term</span><br><span class="line">            self.w_0 = np.mean(w_0s)</span><br><span class="line">            print(<span class="string">"The computed intercept term is &#123;0:f&#125;"</span>.format(self.w_0))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.margin == <span class="string">'hard'</span> <span class="keyword">and</span> self.evaluate_acc(X, y) &lt; <span class="number">1.0</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">'Hard margin, but data not separable'</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"The rate of support vectors: &#123;0:0.6f&#125;"</span>.format(float(len(self.a))/n))</span><br><span class="line">        caches[<span class="string">'sol'</span>] = sol</span><br><span class="line">        caches[<span class="string">'K'</span>] = K</span><br><span class="line">        caches[<span class="string">'sv_idx'</span>] = sv_idx</span><br><span class="line">        <span class="keyword">return</span> caches</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_no_bias</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.k == <span class="string">'linear'</span>:</span><br><span class="line">            <span class="keyword">return</span> np.dot(x, self.w)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            n, f = x.shape</span><br><span class="line">            preds = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">                pred = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(len(self.a)):</span><br><span class="line">                    pred += self.sv_y[j] * self.a[j] * self.kernel(self.sv_x[j], x[i])</span><br><span class="line">                preds.append(pred)</span><br><span class="line">            <span class="keyword">return</span> np.array(preds)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment">## add bias to the prediction</span></span><br><span class="line">        pred = self.predict_no_bias(x)</span><br><span class="line">        <span class="keyword">return</span> np.sign(pred + self.w_0)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate_acc</span><span class="params">(self, x, y)</span>:</span></span><br><span class="line">        n , f = x.shape</span><br><span class="line">        pred = self.predict(x)</span><br><span class="line">        acc = np.sum(pred == y) / len(y)</span><br><span class="line">        <span class="keyword">return</span> acc</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_Roc</span><span class="params">(self, x_input, y_input)</span>:</span></span><br><span class="line">        n, f = x_input.shape</span><br><span class="line">        pred = self.predict_no_bias(x_input)</span><br><span class="line">        <span class="comment">## argsort</span></span><br><span class="line">        p = np.argsort(pred, axis=<span class="number">0</span>)</span><br><span class="line">        x = x_input[p] </span><br><span class="line">        y = y_input[p] <span class="comment">## labels after sorting</span></span><br><span class="line">        pre = pred[p] <span class="comment">## prediction without bias after sorting</span></span><br><span class="line">        min_dis = min(pred)</span><br><span class="line">        max_dis = max(pred)</span><br><span class="line">        </span><br><span class="line">        true_lbs = np.sum(y == <span class="number">1</span>)</span><br><span class="line">        false_lbs = np.sum(y == <span class="number">-1</span>)</span><br><span class="line">        </span><br><span class="line">        b = np.linspace(min_dis, max_dis, <span class="number">200</span>)</span><br><span class="line">        b = b[::<span class="number">-1</span>]</span><br><span class="line">        tprs = []</span><br><span class="line">        fprs = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i, t <span class="keyword">in</span> enumerate(b):</span><br><span class="line">            TP = <span class="number">0</span></span><br><span class="line">            FP = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">                <span class="keyword">if</span> pre[j] &gt; t:</span><br><span class="line">                    <span class="keyword">if</span> y[j] == <span class="number">1</span>:</span><br><span class="line">                        TP += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> y[j] == <span class="number">-1</span>:</span><br><span class="line">                        FP += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            tprs.append(TP/(true_lbs))</span><br><span class="line">            fprs.append(FP/(false_lbs))</span><br><span class="line">        auc = np.trapz(tprs, fprs)</span><br><span class="line">        plt.figure(figsize=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        plt.plot(fprs, tprs, color=<span class="string">'darkorange'</span>, label=<span class="string">'ROC curve: AUC=&#123;0:0.8f&#125;'</span>.format(auc))</span><br><span class="line">        plt.xlabel(<span class="string">'False Positive Rate'</span>,fontsize=<span class="number">12</span>)</span><br><span class="line">        plt.ylabel(<span class="string">'True Positive Rate'</span>,fontsize=<span class="number">12</span>)</span><br><span class="line">        plt.legend(loc=<span class="string">"lower right"</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">        plt.show()  </span><br><span class="line">        <span class="keyword">return</span> tprs, fprs</span><br></pre></td></tr></table></figure>
<p>That’s it. </p>

    </article>
    <!-- 前后页  -->
    <ul class="post-pager">
        
        
            <li class="previous">
                <a href= "/2018/02/01/Deep-Neural-NetWork-Sorting/" title= Deep Neural NetWork Sorting >
                    <span>Previous Post</span>
                    <span>Deep Neural NetWork Sorting</span>
                </a>
            </li>
        
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
<div id="container"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
    var gitment = new Gitment({
        id: "Support Vector Machine Implementation With Python", // 可选。默认为 location.href
        owner: 'wushbin',
        repo: 'wushbin.github.io',
        oauth: {
            client_id: '17eb7cee5fa4bc08355b',
            client_secret: '176f2991889fafe11f2ae7670c5f1dbe879ce0eb',
        },
    })
    gitment.render('container')

</script>

    <!--PC版-->

    <!--PC版-->


    
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:ngshbin@gmail.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/wushbin" class="iconfont-archer github" target="_blank" title="github"></a>
            
        
    
        
    
        
            
                <a href="https://www.linkedin.com/in/shengbin-wu/" class="iconfont-archer linkedin" target="_blank" title="linkedin"></a>
            
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">Theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper">
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#SVM-Classifier"><span class="toc-number">1.</span> <span class="toc-text">SVM Classifier</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hard-Margin-SVM"><span class="toc-number">1.1.</span> <span class="toc-text">Hard Margin SVM</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Making-prediction-using-Linear-Kernel"><span class="toc-number">1.1.1.</span> <span class="toc-text">Making prediction using Linear Kernel</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Gaussian-Kernel-RBF"><span class="toc-number">1.1.2.</span> <span class="toc-text">Gaussian Kernel(RBF)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Soft-Margin"><span class="toc-number">1.2.</span> <span class="toc-text">Soft Margin</span></a></li></ol></li></ol>
    </div>
    
    <div class="back-top">&#xe639;</div>
    <div class="sidebar">
    <div class="sidebar-header sidebar-header-show-archive">
        <div class="sidebar-category">
            <span class="sidebar-archive-link"><span class="iconfont-archer">&#xe67d;</span>Archive</span>
            <span class="sidebar-tags-link"><span class="iconfont-archer">&#xe610;</span>Tag</span>
        </div>
    </div>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-archive">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-archive"> Total : 12 </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2018 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/01</span><a class="archive-post-title" href= "/2018/03/01/Support-Vector-Machine-Implementation/" >Support Vector Machine Implementation With Python</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/01</span><a class="archive-post-title" href= "/2018/02/01/Deep-Neural-NetWork-Sorting/" >Deep Neural NetWork Sorting</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2017 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/23</span><a class="archive-post-title" href= "/2017/12/23/Speech-Recognition/" >Speech Recognition</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/23</span><a class="archive-post-title" href= "/2017/12/23/PacMan-Game-Artificial-Intellegence/" >PacMan Game: Artificial Intellegence</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/23</span><a class="archive-post-title" href= "/2017/12/23/Optical-Character-Recognition/" >Optical Character Recognition</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/12</span><a class="archive-post-title" href= "/2017/10/12/Sharing-On-Campus-Web-Application/" >Sharing On Campus: Web Application</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/09</span><a class="archive-post-title" href= "/2017/10/09/Word-Embedding-Syntactics-or-Semantics/" >Word Embedding: Syntactics or Semantics</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/23</span><a class="archive-post-title" href= "/2017/09/23/Hidden-Markov-Model-for-Part-of-Speech-Tagging/" >Hidden Markov Model for Part of Speech Tagging</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/02</span><a class="archive-post-title" href= "/2017/05/02/cat-and-dog/" >cat-and-dog</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/01</span><a class="archive-post-title" href= "/2017/05/01/Duke-Gather-Android-Application/" >Duke Gather: Android Application</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2016 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/01</span><a class="archive-post-title" href= "/2016/06/01/High-Speed-Test-Rig-Development/" >High Speed Test Rig Development</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2013 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/01</span><a class="archive-post-title" href= "/2013/06/01/SCARA-Robot/" >SCARA Robot</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name"><a href= "#">Java</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Mobile Application</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">machine learning</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">natural language processing</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">mechanical design</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">experiment</a></span>
    
    </div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: false
    tags: true</pre>
    </div> 
    <div class="sidebar-tag-list"></div>
</div>
    </div>
</div> 
    <script>
    var jsInfo = {
        root: '/'
    }
</script>
    <!-- 不蒜子  -->
    
    <!-- CNZZ统计  -->
    
    </div>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>

<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

</body>
</html>


