<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>wushbin&#39;s studio</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wushbin.github.io/"/>
  <updated>2017-12-23T13:54:37.995Z</updated>
  <id>https://wushbin.github.io/</id>
  
  <author>
    <name>shengbin wu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PacMan Game: Artificial Intellegence</title>
    <link href="https://wushbin.github.io/2017/12/23/PacMan-Game-Artificial-Intellegence/"/>
    <id>https://wushbin.github.io/2017/12/23/PacMan-Game-Artificial-Intellegence/</id>
    <published>2017-12-24T02:54:37.000Z</published>
    <updated>2017-12-23T13:54:37.995Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hidden Markov Model for Part of Speech Tagging</title>
    <link href="https://wushbin.github.io/2017/12/23/Hidden-Markov-Model-for-Part-of-Speech-Tagging/"/>
    <id>https://wushbin.github.io/2017/12/23/Hidden-Markov-Model-for-Part-of-Speech-Tagging/</id>
    <published>2017-12-24T02:53:54.000Z</published>
    <updated>2017-12-23T13:55:18.807Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="machine learning" scheme="https://wushbin.github.io/tags/machine-learning/"/>
    
      <category term="natural language processing" scheme="https://wushbin.github.io/tags/natural-language-processing/"/>
    
  </entry>
  
  <entry>
    <title>Optical Character Recognition</title>
    <link href="https://wushbin.github.io/2017/12/23/Optical-Character-Recognition/"/>
    <id>https://wushbin.github.io/2017/12/23/Optical-Character-Recognition/</id>
    <published>2017-12-24T02:53:38.000Z</published>
    <updated>2017-12-23T13:53:38.203Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Speech Recognition</title>
    <link href="https://wushbin.github.io/2017/12/23/Speech-Recognition/"/>
    <id>https://wushbin.github.io/2017/12/23/Speech-Recognition/</id>
    <published>2017-12-24T02:51:56.000Z</published>
    <updated>2017-12-23T13:51:56.572Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Sharing On Campus: Web Application</title>
    <link href="https://wushbin.github.io/2017/10/12/Sharing-On-Campus-Web-Application/"/>
    <id>https://wushbin.github.io/2017/10/12/Sharing-On-Campus-Web-Application/</id>
    <published>2017-10-13T01:41:29.000Z</published>
    <updated>2017-12-23T13:49:30.688Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Word Embedding: Syntactics or Semantics</title>
    <link href="https://wushbin.github.io/2017/10/09/Word-Embedding-Syntactics-or-Semantics/"/>
    <id>https://wushbin.github.io/2017/10/09/Word-Embedding-Syntactics-or-Semantics/</id>
    <published>2017-10-10T01:39:09.000Z</published>
    <updated>2017-12-23T13:49:53.526Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="machine learning" scheme="https://wushbin.github.io/tags/machine-learning/"/>
    
      <category term="natural language processing" scheme="https://wushbin.github.io/tags/natural-language-processing/"/>
    
  </entry>
  
  <entry>
    <title>cat-and-dog</title>
    <link href="https://wushbin.github.io/2017/05/02/cat-and-dog/"/>
    <id>https://wushbin.github.io/2017/05/02/cat-and-dog/</id>
    <published>2017-05-03T00:42:35.000Z</published>
    <updated>2017-12-23T13:49:09.193Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>In the note, a classifier of SVM(Support Vector Machine) and a classifier of CNN(Convolutional Neural Network) using transfer learning will be explored to experiment the accuracy of automatically classifying the image set of cats and dogs.  </p><h4 id="Method-One"><a href="#Method-One" class="headerlink" title="Method One"></a>Method One</h4><p>For the first method, an SVM classifier was trained to classify the images by families(family dog or family cat). SIFT will be applied to extracted the features from each image in the training set. Then the bag of word model will be applied to create a dictionary for these extracted features. This dictionary is formed by a clustering algorithm K-means. One cluster of features is viewed as a visual word in this dictionary. After the dictionary is created, images are represented by frequency vectors which represent the proportion of features belong to a visual word. Then, a SVM classifier is trained based on these frequency features.  </p><h4 id="Method-Two"><a href="#Method-Two" class="headerlink" title="Method Two"></a>Method Two</h4><p>For the second method, we used CNN model to extracted features from the images. For this project, keras application are used. These applications are deep learning models with pre-trained weights. They can be used for prediction, feature extraction and fine tuning. The ResNet50, InceptionV3 and Xception model are used for extracting features from the images. Then these features will be used to trained a CNN model.  </p><h4 id="Data-Set"><a href="#Data-Set" class="headerlink" title="Data Set"></a>Data Set</h4><p>The data set for this project is the provided by Microsoft Research and Kaggle. The training set consists of 25,000 images with half cat images and half dog images. The training set contains 12,500 images without labels. The size of these images are about $350\times 350$.<br>After downloading the image set from Kaggle, the images are separated into two folder, one for cat images, one for dog images. For dogs, the corresponding label is 1, for cats, the corresponding label is 0. The sample images in the data set are shown in the <strong><em>Figure 1</em></strong>.<br><img src="/images/catAndDog.png" alt="data set images">“Figure 1: images in data set”</p><h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><h4 id="Method-One-Traditional-Machine-Learning-Approach"><a href="#Method-One-Traditional-Machine-Learning-Approach" class="headerlink" title="Method One: Traditional Machine Learning Approach"></a>Method One: Traditional Machine Learning Approach</h4><p>For traditional image classification problems, features extracted by human are chosen to train classifiers. Then feature descriptors are use to represent the images. SIFT, HoG, RGB and HSV are the common features that are used to represent images.<br>For this project, SIFT are used to extracted the features and compute the feature descriptors. Because we know that the shapes of images of cat and dog are different with each other. Features extracted by SIFT will play an important role in the classification of the image set.<br>After implementing the SIFT algorithms to extract features, we get the features descriptors of all the images in the training set. K-means clustering algorithms is applied to generate a dictionary of visual words for the features descriptors in the training set. All the images are then represented by by frequency vectors which represent the proportion of features belong to a visual word.<br>Based on the frequency vectors generated by the BOW method, a SVM classifier was trained to make classification. The visualize process of this method is shown in the <strong><em>Figure 2</em></strong>.<br><img src="/images/SIFT_proc.jpeg" alt="method one">“Figure 2: Process of Method One”</p><p><a href="https://github.com/wushbin/DogAndCat/blob/master/catVsDog.ipynb" target="_blank" rel="noopener">Source code for this method</a><br>The accuracy of this method is about $62\%$ when the images were compressed to $128 \times 128$, which is quite dissatisfactory for a binary classification problem. While when the images were compressed to $256 \times 256$, the accuracy only increase to $65.46\%$.<br><img src="/images/sift_result.png" alt="method one result">“Result using Method One”</p><h4 id="Method-Two-Deep-Neural-Netword-CNN-with-transfer-learning"><a href="#Method-Two-Deep-Neural-Netword-CNN-with-transfer-learning" class="headerlink" title="Method Two: Deep Neural Netword(CNN with transfer learning)"></a>Method Two: Deep Neural Netword(CNN with transfer learning)</h4><p><em>Method two is refer to Peiwen Yang’s Post in Zhihu</em>.  </p><p>In Method Two, image features will be extracted by a Convolutional Neural Network model. After that, we can simply use dropout to classify the validation set and test set. Compared with the feature extraction by SIFT, convolutional neural network learn features from the images.<br>Several pre-trained model in keras application are used in this method to learn the features from the cat and dog image set. The ResNet50, InceptionV3 and Xception models are chosen to learn the features,which are object detection model in image recognition provided by keras. The weights of these models are pre-trained on ImageNet.<br>In order to improve the performance of the classification model, these three models are used together to learn the features from the images. These three models build up a huge network. If a fully connected layer is added directly after this huge network to train the classification model, the computation cost will be extremely large. Thus, the features extraction and classifier training are conducted separately. The pre-trained models are used to extract features. And then, these features are used to train the classifier.<br>For the trainning process, a simple neural network was used as the classification model, this model includes an input layer, a hidden layer with dropout rate $0.5$, and an output layer with sigmoid as activation function. The features number learned by each model is 2048, and then 6144 features was learned from the feature extraction process. The number of nodes in the input layer is 6144. For the hidden layer, there is also 6144 nodes, but they are not fully connected because dropout was applied in this layer. For the output layer, there is only 1 node because it is a binary classification problem.\newline<br>With fine features learning by pre-trained models, a simple model can make a good classification. The visualized process of this model is shown is <strong><em>Figure 3</em></strong>.<br><img src="/images/cnnModel.jpeg" alt="method two">“Figure 3: Model of Method Two”</p><p><a href="https://github.com/wushbin/DogAndCat/blob/master/cnnCatVsDog.ipynb" target="_blank" rel="noopener">Source code for this method</a> </p><p><img src="/images/cnn_result.png" alt="method two result">“Result using Method two”<br>In addition, the cost time of feature extraction for each model(ResNet50, InceptionV3 and Xception) is less than 20 minutes, which is also more efficient than the method one. Moreover, it only take less than 10 minutes to train the classifier.   </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;p&gt;In the note, a classifier of S
      
    
    </summary>
    
    
      <category term="machine learning" scheme="https://wushbin.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Duke Gather: Android Application</title>
    <link href="https://wushbin.github.io/2017/05/01/Duke-Gather-Android-Application/"/>
    <id>https://wushbin.github.io/2017/05/01/Duke-Gather-Android-Application/</id>
    <published>2017-05-02T01:40:30.000Z</published>
    <updated>2017-12-23T13:47:06.979Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="Java" scheme="https://wushbin.github.io/tags/Java/"/>
    
      <category term="Mobile Application" scheme="https://wushbin.github.io/tags/Mobile-Application/"/>
    
  </entry>
  
  <entry>
    <title>High Speed Test Rig Development</title>
    <link href="https://wushbin.github.io/2016/06/01/High-Speed-Test-Rig-Development/"/>
    <id>https://wushbin.github.io/2016/06/01/High-Speed-Test-Rig-Development/</id>
    <published>2016-06-02T01:53:03.000Z</published>
    <updated>2018-01-13T21:18:41.657Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>这是一个失败的试验台设计，试验过程及数据详见文末论文链接。<br>本项目主要是搭建一个综合实验台,该实验台用以研究一款气体动压轴承和一款气体静压轴承的在高速旋转状态下的动态特性。<br>本文的研究重点主要有以下几个方面:</p><ol><li>设计开发一个用以研究气体箔片止推轴承和多孔质静压气体轴承的实验台,实验台主要包括高速旋转部分,加载部分、供气系统和数据采集系统。其中高速旋转部分采用多孔质静压气体轴承作为转子径向支撑,实验台的轴向限位采用气体箔片止推轴承。采用XLrotor转子动力学软件对高速旋转部分的转子进行分析,结果表明该转子在设计的转速内能稳定工作。</li><li>尝试并开发气体箔片止推轴承的制作工艺。根据总结出来的工艺,制作了五种不同结构的气体箔片止推轴承,并对其进行实验研究。</li><li>对实验台高速旋转部分的轴承-转子系统进行了动平衡实验和转子动力学实验。动平衡实验包括单面动平衡和双面动平衡实验。转子动力学实验研究多孔质静压气体轴承对高速转子性能的影响。</li></ol><h3 id="试验台设计"><a href="#试验台设计" class="headerlink" title="试验台设计"></a>试验台设计</h3><p>试验台主要由加载部分和高速旋转部分两部分组成<br><img src="/images/High-Speed-Test-Rig-Development/Picture1.png" style="width: 800px;"></p><h4 id="试验台加载部分"><a href="#试验台加载部分" class="headerlink" title="试验台加载部分"></a>试验台加载部分</h4><p><img src="/images/High-Speed-Test-Rig-Development/Picture2.jpg" style="width: 800px;"></p><h4 id="试验台高速旋转部分"><a href="#试验台高速旋转部分" class="headerlink" title="试验台高速旋转部分"></a>试验台高速旋转部分</h4><p><img src="/images/High-Speed-Test-Rig-Development/Picture3.jpg" style="width: 800px;"></p><h4 id="试验台供气系统"><a href="#试验台供气系统" class="headerlink" title="试验台供气系统"></a>试验台供气系统</h4><p><img src="/images/High-Speed-Test-Rig-Development/Picture4.png" style="width: 500px;"></p><h4 id="试验台整体"><a href="#试验台整体" class="headerlink" title="试验台整体"></a>试验台整体</h4><p><img src="/images/High-Speed-Test-Rig-Development/Picture5.png" style="width: 800px;"></p><h4 id="转子动平衡试验台"><a href="#转子动平衡试验台" class="headerlink" title="转子动平衡试验台"></a>转子动平衡试验台</h4><p><img src="/images/High-Speed-Test-Rig-Development/Picture6.png" style="width: 500px;"><br><img src="/images/High-Speed-Test-Rig-Development/Picture7.png" style="width: 500px;"></p><h3 id="试验台加工制造以及试验部分（见论文）"><a href="#试验台加工制造以及试验部分（见论文）" class="headerlink" title="试验台加工制造以及试验部分（见论文）"></a>试验台加工制造以及试验部分（见论文）</h3><p><a href="http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&amp;dbname=CMFD201701&amp;filename=1016251956.nh&amp;v=MDAwMzZyV00xRnJDVVJMS2ZadWRyRmkzaFdyM0xWRjI2R0xHOUg5akpxWkViUElSOGVYMUx1eFlTN0RoMVQzcVQ=" target="_blank" rel="noopener">论文链接</a> </p><h4 id="气体箔片止推轴承制造工艺"><a href="#气体箔片止推轴承制造工艺" class="headerlink" title="气体箔片止推轴承制造工艺"></a>气体箔片止推轴承制造工艺</h4><h4 id="箔片止推轴承性能测试"><a href="#箔片止推轴承性能测试" class="headerlink" title="箔片止推轴承性能测试"></a>箔片止推轴承性能测试</h4><h4 id="高速转自动平衡试验"><a href="#高速转自动平衡试验" class="headerlink" title="高速转自动平衡试验"></a>高速转自动平衡试验</h4><h4 id="多孔质轴承-转子系统试验"><a href="#多孔质轴承-转子系统试验" class="headerlink" title="多孔质轴承-转子系统试验"></a>多孔质轴承-转子系统试验</h4><hr><p>于2016年夏天<br>导师：没有导师<br><a href="">试验台UG三维模型及详细工程图</a><br><a href="http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&amp;dbname=CMFD201701&amp;filename=1016251956.nh&amp;v=MDAwMzZyV00xRnJDVVJMS2ZadWRyRmkzaFdyM0xWRjI2R0xHOUg5akpxWkViUElSOGVYMUx1eFlTN0RoMVQzcVQ=" target="_blank" rel="noopener">论文链接</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;这是一个失败的试验台设计，试验过程及数据详见文末论文链接。&lt;br&gt;本项目主要是搭建一个综合实验台,该实验台用以研究一款气体动压轴承和一款气体
      
    
    </summary>
    
    
      <category term="mechanical design" scheme="https://wushbin.github.io/tags/mechanical-design/"/>
    
      <category term="experiment" scheme="https://wushbin.github.io/tags/experiment/"/>
    
  </entry>
  
  <entry>
    <title>SCARA Robot</title>
    <link href="https://wushbin.github.io/2013/06/01/SCARA-Robot/"/>
    <id>https://wushbin.github.io/2013/06/01/SCARA-Robot/</id>
    <published>2013-06-02T01:52:32.000Z</published>
    <updated>2018-01-13T21:18:45.856Z</updated>
    
    <content type="html"><![CDATA[<h3 id="SCARA机器人"><a href="#SCARA机器人" class="headerlink" title="SCARA机器人"></a>SCARA机器人</h3><p>SCARA平面关节式机器人是目前使用较为广泛的通用型机器人。在动作相对简单，而又需要有高产量的环境中，SCARA机器人相比六轴机器人而言很有优势的。SCARA机器人在点对点的运动中是最好的机器人，常用于分配、搬运、装载、包装、安放以及装配等作业之中。<br><img src="/images/SCARA-Robot/Picture0.jpg" style="width: 600px;"></p><h3 id="机器人本体机械设计"><a href="#机器人本体机械设计" class="headerlink" title="机器人本体机械设计"></a>机器人本体机械设计</h3><h4 id="机器人构型"><a href="#机器人构型" class="headerlink" title="机器人构型"></a>机器人构型</h4><p>两种比较具有代表性的SCARA机器人的构型，初步选择了两种方案，如下图所示：</p><ol><li>RRRT型SCARA机器人</li><li>TRRR型SCARA机器人<br><img src="/images/SCARA-Robot/Picture1.jpg" style="width: 400px;"><h4 id="机器人技术参数"><a href="#机器人技术参数" class="headerlink" title="机器人技术参数"></a>机器人技术参数</h4>该款SCARA机器人的关键设计参数如下图所示。<br><img src="/images/SCARA-Robot/Picture2.jpg" style="width: 600px;"></li></ol><h4 id="机器人传动方式"><a href="#机器人传动方式" class="headerlink" title="机器人传动方式"></a>机器人传动方式</h4><p>该四自由度关节型工业机器人各个轴的传动方案确定如下：</p><ul><li>Ｘ轴回转：底座→伺服电机→谐波减速器→大臂回转</li><li>Ｙ轴回转：大臂→伺服电机→谐波减速器→小臂回转 </li><li>Ｚ轴移动：小臂→伺服电机→同步带→丝杆螺母副→滚珠花键副上下平动</li><li>Ｒ轴回转：小臂→伺服电机→同步带→谐波减速器→滚珠花键轴套→滚珠花键副<br><img src="/images/SCARA-Robot/Picture3.jpg" style="width: 600px;"></li></ul><h4 id="机器人尺寸及工作空间"><a href="#机器人尺寸及工作空间" class="headerlink" title="机器人尺寸及工作空间"></a>机器人尺寸及工作空间</h4><p>机器人的整体设计结构如下图所示<br><img src="/images/SCARA-Robot/Picture4.jpg" style="width: 800px;"></p><p>机器人的整体尺寸以及工作空间如下图所示</p><p><img src="/images/SCARA-Robot/Picture5.jpg" style="width: 800px;"></p><p>机器人整体渲染效果图</p><p><img src="/images/SCARA-Robot/Picture6.jpg" style="width: 800px;"></p><h3 id="机器人关键结构设计"><a href="#机器人关键结构设计" class="headerlink" title="机器人关键结构设计"></a>机器人关键结构设计</h3><h4 id="机械臂一结构设计"><a href="#机械臂一结构设计" class="headerlink" title="机械臂一结构设计"></a>机械臂一结构设计</h4><p>电机固定在底座上，有利于减少机械臂的惯量。所选的谐波减速器为日本哈默纳科简易型谐波减速器SHG/SHF类型，该类型谐波属于简易型谐波减速器，内部置有用于支撑外部负载的精密、具有高刚性的交叉滚子轴承，不用再在外部安装用于支承负载的轴承，所以只需将刚轮、柔轮分别与底座和机械臂一固定，就能实现X轴的转动。<br><img src="/images/SCARA-Robot/Picture7.jpg" style="width: 400px;"></p><h4 id="机械臂手腕结构设计"><a href="#机械臂手腕结构设计" class="headerlink" title="机械臂手腕结构设计"></a>机械臂手腕结构设计</h4><p>由于主轴位于机器人小臂的末端，对重量和惯量比较敏感，所以要求整个结构紧凑、重量轻，同时考虑到控制系统设计的相对简单和成本的相对低廉，采用滚珠花键和滚珠螺杆组合的方式。目前SCARA机器人最新的结构是采用滚珠花键-丝杆一体的结构，但这样的结构需要两个电机耦合控制来实现末端的旋转和上下移动，使控制系统较为复杂。</p><p><img src="/images/SCARA-Robot/Picture8.jpg" style="width: 600px;"></p><h3 id="机器人运动学分析"><a href="#机器人运动学分析" class="headerlink" title="机器人运动学分析"></a>机器人运动学分析</h3><h4 id="工业机器人运动学方程"><a href="#工业机器人运动学方程" class="headerlink" title="工业机器人运动学方程"></a>工业机器人运动学方程</h4><p><img src="/images/SCARA-Robot/Picture9.jpg" style="width: 400px;"><br><img src="/images/SCARA-Robot/Picture10.jpg" style="width: 400px;"></p><h4 id="该SCARAb机器人D-H模型"><a href="#该SCARAb机器人D-H模型" class="headerlink" title="该SCARAb机器人D-H模型"></a>该SCARAb机器人D-H模型</h4><p>根据所设计的SCARA机器人结构，机器人D-H坐标系如下图所示<br><img src="/images/SCARA-Robot/Picture11.jpg" style="width: 400px;"><br>其连杆参数表如下图所示<br><img src="/images/SCARA-Robot/Picture12.jpg" style="width: 600px;"></p><h4 id="正运动学分析"><a href="#正运动学分析" class="headerlink" title="正运动学分析"></a>正运动学分析</h4><p>各连杆变换矩阵连乘，便能得到机器人末端连杆的位姿方程，也就是正运动学方程。<br><img src="/images/SCARA-Robot/Picture13.jpg" style="width: 600px;"></p><h4 id="逆运动学分析"><a href="#逆运动学分析" class="headerlink" title="逆运动学分析"></a>逆运动学分析</h4><p>在四自由度关节型机器人基坐标系中，机械手末端执行器的位姿矢量设为已知<br><img src="/images/SCARA-Robot/Picture15.jpg" style="width: 200px;"><br>也就是<br><img src="/images/SCARA-Robot/Picture16.jpg" style="width: 800px;"><br>最终可求得<br><img src="/images/SCARA-Robot/Picture17.jpg" style="width: 800px;"></p><hr><p>于2013年<br>导师：王念峰<br>华南理工大大学<br>源文件下载链接<br><a href="">solidworks模型及工程图</a>  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;SCARA机器人&quot;&gt;&lt;a href=&quot;#SCARA机器人&quot; class=&quot;headerlink&quot; title=&quot;SCARA机器人&quot;&gt;&lt;/a&gt;SCARA机器人&lt;/h3&gt;&lt;p&gt;SCARA平面关节式机器人是目前使用较为广泛的通用型机器人。在动作相对简单，而又需要有高产量
      
    
    </summary>
    
    
      <category term="mechanical design" scheme="https://wushbin.github.io/tags/mechanical-design/"/>
    
      <category term="experiment" scheme="https://wushbin.github.io/tags/experiment/"/>
    
  </entry>
  
</feed>
